{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPnvcJJmeEa3rUOgWLqZV2j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Imports and device setup"],"metadata":{"id":"tTrO-X0DCyEW"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKbaIXZAfkSi","executionInfo":{"status":"ok","timestamp":1732921053438,"user_tz":-330,"elapsed":407,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}},"outputId":"26a28449-c52e-4cc1-d49d-ee66cc2007f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Torch version: 2.5.1+cu121\n","Torchvision version: 0.20.1+cu121\n","Device we use: cpu\n"]}],"source":["# Import necessary libraries\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import xarray as xr\n","import zipfile\n","import os\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","from torch.utils.data import random_split, DataLoader\n","\n","import torch\n","import torchvision\n","from PIL import Image\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# Check PyTorch and torchvision versions\n","print(\"Torch version:\", torch.__version__)\n","print(\"Torchvision version:\", torchvision.__version__)\n","\n","# Set device to GPU if available else go with cpu\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device we use:\", device)\n"]},{"cell_type":"markdown","source":["#### Unzip Datasets(in G.Drive): image_train, image_test"],"metadata":{"id":"p0SgqcVsC7AW"}},{"cell_type":"code","source":["from google.colab import drive\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# UNZIPPING THE DATASETS\n","with zipfile.ZipFile('/content/drive/MyDrive/finetuning/images_training_rev1.zip', 'r') as zip_ref:\n","    zip_ref.extractall('/content/image_train')\n","\n","# Path to the main zip file\n","zip_file_path = '/content/drive/MyDrive/finetuning/images_test_rev1.zip'\n","output_dir = '/content/image_test'\n","\n","# Create output directory if it doesn't exist\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Function to recursively unzip files\n","def unzip_all(zip_path, extract_to):\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_to)\n","        for root, _, files in os.walk(extract_to):\n","            for file in files:\n","                if file.endswith('.zip'):\n","                    nested_zip_path = os.path.join(root, file)\n","                    nested_output_dir = os.path.join(root, file.replace('.zip', ''))\n","                    os.makedirs(nested_output_dir, exist_ok=True)\n","                    unzip_all(nested_zip_path, nested_output_dir)  # Recursively unzip nested zip files\n","                    os.remove(nested_zip_path)  # Optionally remove nested zip file after extraction\n","\n","# Unzip the main file and handle nested zips\n","unzip_all(zip_file_path, output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kscm10uSg2oa","executionInfo":{"status":"ok","timestamp":1732921166208,"user_tz":-330,"elapsed":108813,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}},"outputId":"4c7d3a95-453c-4b97-f789-f4bea0b9d2d0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#### Organize unzipped files"],"metadata":{"id":"QxVHlYVTDUHk"}},{"cell_type":"code","source":["# LOADING IMAGE PATH IMAGES AND LABELS\n","image_dir = '/content/image_train/images_training_rev1'  # Path to training images\n","labels_path = '/content/training_solutions_rev1.csv'  # Path to labels CSV\n","\n","# Load labels\n","labels_df = pd.read_csv(labels_path)\n","print(\"Labels loaded:\", labels_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-A7hzjRMDIpF","executionInfo":{"status":"ok","timestamp":1732921166208,"user_tz":-330,"elapsed":6,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}},"outputId":"a5810975-b0f9-43cb-fee2-a73f543dcebd"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Labels loaded: (61578, 38)\n"]}]},{"cell_type":"markdown","source":["# 2.PreProcessing Data"],"metadata":{"id":"a2cnSMdFHzz_"}},{"cell_type":"code","source":["# DATA AUGUMENTATIONA AND NORMALIZATION FOR TRAINING\n","transform = transforms.Compose([\n","    transforms.Resize((100, 100)),    # Resize to 100x100 if needed\n","    transforms.ToTensor(),            # Convert to tensor\n","    transforms.Normalize((0.5,), (0.5,))  # Normalize\n","])\n"],"metadata":{"id":"E8wTokvNH7am","executionInfo":{"status":"ok","timestamp":1732921261764,"user_tz":-330,"elapsed":673,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","#CUSTOM DTASET CLASS(GALAXY DATASET) FOR LOADING IMAGES AND LABELS AS TENSORS\n","class GalaxyDataset(torch.utils.data.Dataset):\n","    def __init__(self, image_dir, labels_df, transform=None):\n","        self.image_dir = image_dir\n","        self.labels_df = labels_df\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.labels_df)\n","\n","    def __getitem__(self, idx):\n","        # Assuming the image filename is in the first column\n","        img_filename = str(self.labels_df.iloc[idx, 0]) + '.jpg'  # Add .jpg extension if needed\n","        img_name = os.path.join(self.image_dir, img_filename)  # Adjust if there's a different file extension\n","\n","        try:\n","            image = Image.open(img_name).convert('RGB')\n","        except FileNotFoundError:\n","            print(f\"Image file not found: {img_name}\")\n","            raise\n","\n","        label = torch.tensor(self.labels_df.iloc[idx, 1:].values, dtype=torch.float32)  # labels as tensor\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n","\n"],"metadata":{"id":"xRteKA_3hcqX","executionInfo":{"status":"ok","timestamp":1732921266020,"user_tz":-330,"elapsed":409,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#### Splitting the Dataset"],"metadata":{"id":"REAyfZe3KGke"}},{"cell_type":"code","source":["# Create dataset and SPLIT TO TRAIN AND VALIDATION SETS AND TEST DATA SETS\n","from torch.utils.data import random_split, DataLoader\n","\n","# Define the dataset\n","dataset = GalaxyDataset(image_dir, labels_df, transform=transform)\n","\n","batch_size = 37  # or any other number you'd like to use for the batch size\n","\n","\n","# Define sizes for train, validation, and test sets\n","train_size = int(0.7 * len(dataset))  # 70% for training\n","valid_size = int(0.15 * len(dataset)) # 15% for validation\n","test_size = len(dataset) - train_size - valid_size  # Remaining 15% for testing\n","\n","# Split the dataset\n","train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n","\n","# Create data loaders for each split\n","trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","validloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n","\n","testloader = DataLoader(test_dataset, batch_size=37, shuffle=False, num_workers=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y7yizFKmhfV3","executionInfo":{"status":"ok","timestamp":1732906955838,"user_tz":-330,"elapsed":1517,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}},"outputId":"f854abd6-df35-4aba-dbb2-7d33e5af82b0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Train batch shape: torch.Size([37, 3, 100, 100])\n","Train labels batch shape: torch.Size([37, 37])\n","Validation batch shape: torch.Size([37, 3, 100, 100])\n","Validation labels batch shape: torch.Size([37, 37])\n","Test batch shape: torch.Size([37, 3, 100, 100])\n","Test labels batch shape: torch.Size([37, 37])\n"]}]},{"cell_type":"code","source":["# Check the shape of a batch from the train loader\n","dataiter = iter(trainloader)\n","images, labels = next(dataiter)  # Use next(dataiter) instead of dataiter.next()\n","print(\"Train batch shape:\", images.shape)\n","print(\"Train labels batch shape:\", labels.shape)\n","\n","# Check the shape of a batch from the validation loader\n","dataiter_valid = iter(validloader)\n","images_valid, labels_valid = next(dataiter_valid)\n","print(\"Validation batch shape:\", images_valid.shape)\n","print(\"Validation labels batch shape:\", labels_valid.shape)\n","\n","# Check the shape of a batch from the test loader\n","dataiter_test = iter(testloader)\n","images_test, labels_test = next(dataiter_test)\n","print(\"Test batch shape:\", images_test.shape)\n","print(\"Test labels batch shape:\", labels_test.shape)\n","\n"],"metadata":{"id":"9kufpcxMJC1I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3.Load Pre-Trained ResNet-50"],"metadata":{"id":"VzYu_2ISD0c_"}},{"cell_type":"code","source":["# Apply LoRA to the model's last layer\n","model_checkpoint = \"microsoft/resnet-50\"\n","model = AutoModelForImageClassification.from_pretrained(\n","    model_checkpoint,\n","    num_labels=37,\n","    ignore_mismatched_sizes=True\n",")"],"metadata":{"id":"-515GvIMDy_P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# LoRA  Implementation"],"metadata":{"id":"q0UHHcYEDhJv"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n","\n","\n","# Define the LoRA adaptation layer\n","class LORALayer(nn.Module):\n","    def __init__(self, adapted_layer, rank=16):\n","        super(LORALayer, self).__init__()\n","        self.adapted_layer = adapted_layer\n","        self.rank = rank\n","        # Initialize low-rank matrices A and B\n","        self.A = nn.Parameter(torch.randn(adapted_layer.weight.size(1), rank) * 0.01)\n","        self.B = nn.Parameter(torch.randn(rank, adapted_layer.weight.size(0)) * 0.01)\n","\n","    def forward(self, x):\n","        # Calculate the low-rank adaptation\n","        low_rank_matrix = self.A @ self.B\n","        adapted_weight = self.adapted_layer.weight + low_rank_matrix.t()\n","        return nn.functional.linear(x, adapted_weight, self.adapted_layer.bias)\n","\n","# Replace the final classification layer with a LoRA layer\n","last_layer = model.classifier[-1]  # Assuming the last layer is linear\n","model.classifier[-1] = LORALayer(last_layer)\n"],"metadata":{"id":"HAuFKBX-f0fw","executionInfo":{"status":"ok","timestamp":1732906962085,"user_tz":-330,"elapsed":2357,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Move model to GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n"],"metadata":{"id":"aEjXqMtcj5r5","executionInfo":{"status":"ok","timestamp":1732906979709,"user_tz":-330,"elapsed":1749,"user":{"displayName":"Srikanth","userId":"11288702543808839877"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# 4.Training Loop with LoRA"],"metadata":{"id":"imH8ivUNB94Y"}},{"cell_type":"code","source":["# Define optimizer, criterion, and scheduler\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","\n","# Training parameters\n","num_epochs = 20\n","best_val_accuracy = 0.0\n","best_model_wts = model.state_dict()\n","\n","# Training loop\n","train_losses, val_losses = [], []\n","train_accuracies, val_accuracies = [], []\n","\n","\n","for epoch in range(num_epochs):\n","\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in trainloader:\n","        images, labels = images.to(device), labels.to(device)\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        logits = outputs.logits  # Extract logits\n","        loss = criterion(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(logits.data, 1)\n","        labels = torch.argmax(labels, dim=1) if labels.ndim > 1 else labels\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    scheduler.step()\n","    train_accuracy = 100 * correct / total\n","    train_losses.append(running_loss / len(trainloader))\n","    train_accuracies.append(train_accuracy)\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, correct, total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in validloader:\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            logits = outputs.logits\n","            loss = criterion(logits, labels)\n","            val_running_loss += loss.item()\n","            _, predicted = torch.max(logits, 1)\n","            labels = torch.argmax(labels, dim=1) if labels.ndim > 1 else labels\n","            correct += (predicted == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_accuracy = 100 * correct / total\n","    val_losses.append(val_running_loss / len(validloader))\n","    val_accuracies.append(val_accuracy)\n","\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        best_model_wts = model.state_dict()\n","\n","    print(f\"Epoch {epoch+1}, Train Loss: {train_losses[-1]}, Train Accuracy: {train_accuracy}%, \"\n","          f\"Val Loss: {val_losses[-1]}, Val Accuracy: {val_accuracy}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6-QB5JBwkZqy","outputId":"b17595d8-8cda-44a7-ec88-ce8e9f6f845c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Train Loss: 14.030124266123034, Train Accuracy: 67.50023219095384%, Val Loss: 14.008434889306983, Val Accuracy: 61.44578313253012%\n","Epoch 2, Train Loss: 13.734673869568867, Train Accuracy: 72.28568774960527%, Val Loss: 13.74241442469708, Val Accuracy: 75.29577770541626%\n","Epoch 3, Train Loss: 13.659757991836653, Train Accuracy: 74.3661186960156%, Val Loss: 13.799186741013125, Val Accuracy: 76.22924128948226%\n","Epoch 4, Train Loss: 13.601468790847411, Train Accuracy: 74.86765115631096%, Val Loss: 13.733461069773478, Val Accuracy: 71.80071637902964%\n","Epoch 5, Train Loss: 13.546703237848183, Train Accuracy: 75.35293024983747%, Val Loss: 13.711249834083649, Val Accuracy: 74.02583306197764%\n","Epoch 6, Train Loss: 13.489349213662425, Train Accuracy: 75.60369647998515%, Val Loss: 13.784153980423648, Val Accuracy: 70.51991750786931%\n","Epoch 7, Train Loss: 13.423629932796832, Train Accuracy: 76.29562552242965%, Val Loss: 13.743887008912113, Val Accuracy: 73.37457939867578%\n","Epoch 8, Train Loss: 13.270955039873156, Train Accuracy: 79.64614098634718%, Val Loss: 13.667750274321161, Val Accuracy: 74.86160859654835%\n","Epoch 9, Train Loss: 13.213792006994032, Train Accuracy: 79.95959877403176%, Val Loss: 13.677548400848266, Val Accuracy: 74.61196135894932%\n","Epoch 10, Train Loss: 13.172100712753243, Train Accuracy: 79.88297575926443%, Val Loss: 13.722843737008581, Val Accuracy: 73.14664061652013%\n","Epoch 11, Train Loss: 13.136883496418852, Train Accuracy: 79.86207857341878%, Val Loss: 13.750315107016199, Val Accuracy: 72.3542819928362%\n","Epoch 12, Train Loss: 13.10760972344179, Train Accuracy: 79.86207857341878%, Val Loss: 13.795099135862296, Val Accuracy: 73.3420167155107%\n","Epoch 13, Train Loss: 13.08167929338016, Train Accuracy: 80.00835887433826%, Val Loss: 13.822300229206622, Val Accuracy: 74.02583306197764%\n","Epoch 14, Train Loss: 13.059150478684206, Train Accuracy: 80.12909817033528%, Val Loss: 13.884941936017999, Val Accuracy: 71.9092586562466%\n","Epoch 15, Train Loss: 13.032336783982634, Train Accuracy: 80.49828178694158%, Val Loss: 13.870243869153372, Val Accuracy: 72.26744817106263%\n","Epoch 16, Train Loss: 13.025870352676234, Train Accuracy: 80.71421937401318%, Val Loss: 13.855895195620127, Val Accuracy: 73.04895256702486%\n","Epoch 17, Train Loss: 13.024218262675701, Train Accuracy: 80.76994520293489%, Val Loss: 13.87537700392635, Val Accuracy: 72.40855313144469%\n","Epoch 18, Train Loss: 13.021826391777221, Train Accuracy: 80.66081545462988%, Val Loss: 13.867320451391748, Val Accuracy: 72.57136654727016%\n"]}]},{"cell_type":"markdown","source":["# 5.Evaluate the Model on Test Split"],"metadata":{"id":"KFgPAuM9CL7l"}},{"cell_type":"code","source":["# Test the model\n","model.eval()\n","correct, total = 0, 0\n","with torch.no_grad():\n","    for images, labels in testloader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        logits = outputs.logits\n","        _, predicted = torch.max(logits, 1)\n","        labels = torch.argmax(labels, dim=1) if labels.ndim > 1 else labels\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","test_accuracy = 100 * correct / total\n","print(f\"Test Accuracy with LoRA: {test_accuracy}%\")\n"],"metadata":{"id":"PSbe_eUmCOoI"},"execution_count":null,"outputs":[]}]}